{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/batiukmaks/NLP-Labs/blob/main/labs/LPNLP7_RNN_Quest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Quest"
      ],
      "metadata": {
        "id": "_Dak_bQPiQeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --ignore-installed http://nlp.band/static/pypy/lpnlp-2023.10.2-py3-none-any.whl"
      ],
      "metadata": {
        "id": "RgDkWE8EqxAP",
        "outputId": "7b9e893e-4fca-49c9-c491-cea60f6c445f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/64.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/167.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/144.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/70.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/126.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "OKfsJ_qOLz_F",
        "outputId": "372ea29d-e00c-4031-8bd4-60871662b6d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lpnlp\n",
        "\n",
        "lab = lpnlp.start(\n",
        "    email=\"maksym.batiuk.kn.2021@lpnu.ua\",  # <---- Ğ—Ğ°Ğ¿Ğ¾Ğ²Ğ½Ñ–Ñ‚ÑŒ Ñ†Ğµ Ğ¿Ğ¾Ğ»Ğµ\n",
        "    lab=\"quest_rnn\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "Bk4wnk7Eq9o2",
        "outputId": "973935eb-e216-4919-d6da-2e6334f3384b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ğ’Ğ°ÑˆĞµ Ğ·Ğ°Ğ²Ğ´Ğ°Ğ½Ğ½Ñ: http://nlp.band/static/quest-rnn/34452750d6b0.zip. Ğ£Ğ´Ğ°Ñ‡Ñ–! â–ˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ñ‚Ğµ Ğ¿Ğ°ĞºĞµÑ‚ Ñ–Ğ· Ğ·Ğ°Ğ²Ğ´Ğ°Ğ½Ğ½ÑĞ¼ Ğ·Ğ° Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½ÑĞ¼ Ğ²Ğ¸Ñ‰Ğµ ^\n",
        "2. ĞŸÑ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ¹Ñ‚Ğµ README\n",
        "3. Ğ’Ğ¸ĞºĞ¾Ğ½Ğ°Ğ¹Ñ‚Ğµ Ğ·Ğ°Ğ²Ğ´Ğ°Ğ½Ğ½Ñ\n",
        "  - Ğ—Ğ°Ğ²Ğ´Ğ°Ğ½Ğ½Ñ Ğ½Ğµ Ğ·Ğ°Ğ»ĞµĞ¶Ğ¸Ñ‚ÑŒ Ğ²Ñ–Ğ´ Ğ¼Ğ¾Ğ²Ğ¸ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼ÑƒĞ²Ğ°Ğ½Ğ½Ñ\n",
        "  - Ğ—Ğ°Ğ²Ğ´Ğ°Ğ½Ğ½Ñ Ğ½Ğµ Ğ·Ğ°Ğ»ĞµĞ¶Ğ¸Ñ‚ÑŒ Ğ²Ñ–Ğ´ Ñ„Ñ€ĞµĞ¹Ğ¼Ğ¾Ğ²Ğ¾Ñ€ĞºÑƒ. Pytorch, NumPy, Keras Ğ°Ğ±Ğ¾ Ğ²Ğ·Ğ°Ğ³Ğ°Ğ»Ñ– Ğ±ĞµĞ· ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½Ñ–Ñ… Ğ±Ñ–Ğ±Ğ»Ñ–Ğ¾Ñ‚ĞµĞº -- Ğ²ÑĞµ Ğ¼Ğ¾Ğ¶Ğ»Ğ¸Ğ²Ğ¾\n",
        "4. Ğ’Ñ–Ğ´Ğ¿Ñ€Ğ°Ğ²Ñ‚Ğµ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ Ğ½Ğ¸Ğ¶Ñ‡Ğµ"
      ],
      "metadata": {
        "id": "HnEFc4gYrPZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.band/static/quest-rnn/34452750d6b0.zip"
      ],
      "metadata": {
        "id": "3Uz86OChMZod",
        "outputId": "845671de-3357-47c5-f115-8b49c33caaef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-02 09:25:31--  http://nlp.band/static/quest-rnn/34452750d6b0.zip\n",
            "Resolving nlp.band (nlp.band)... 51.12.243.211\n",
            "Connecting to nlp.band (nlp.band)|51.12.243.211|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 518811 (507K) [application/zip]\n",
            "Saving to: â€˜34452750d6b0.zipâ€™\n",
            "\n",
            "34452750d6b0.zip    100%[===================>] 506.65K  1008KB/s    in 0.5s    \n",
            "\n",
            "2024-11-02 09:25:32 (1008 KB/s) - â€˜34452750d6b0.zipâ€™ saved [518811/518811]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 34452750d6b0.zip"
      ],
      "metadata": {
        "id": "UWWSFNNaMecP",
        "outputId": "d884d6ce-7173-4828-c56f-9692601bf788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  34452750d6b0.zip\n",
            " extracting: embedding.weight.json   \n",
            " extracting: W_h.weight.json         \n",
            " extracting: W_h.bias.json           \n",
            " extracting: U_h.weight.json         \n",
            " extracting: U_h.bias.json           \n",
            " extracting: W_y.weight.json         \n",
            " extracting: vocab.json              \n",
            " extracting: quest.bin               \n",
            " extracting: README                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import json"
      ],
      "metadata": {
        "id": "uAjD7GxjN8Sx"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ElmanRNN(nn.Module):\n",
        "    def __init__(self, embedding_dim=48, hidden_dim=160, vocab_size=133):\n",
        "        super(ElmanRNN, self).__init__()\n",
        "\n",
        "        # Initialize dimensions\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.W_h = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.U_h = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.W_y = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, message):\n",
        "        # Initialize hidden state (h_0)\n",
        "        h_t = torch.zeros(message.size(0), self.hidden_dim, device=message.device)\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(message.size(1)):\n",
        "            # Embedding lookup for x_t\n",
        "            if t == 0:\n",
        "                x_t = self.embedding(message[:, t])  # Use the input at time step 0\n",
        "            else:\n",
        "                x_t = self.embedding(message_t)  # Use predicted token from previous step\n",
        "\n",
        "            # Update hidden state using Elman RNN equations\n",
        "            h_t = torch.tanh(self.W_h(x_t) + self.U_h(h_t))\n",
        "\n",
        "            # Compute output and save the prediction\n",
        "            y_t = self.W_y(h_t)\n",
        "            outputs.append(y_t.unsqueeze(1))\n",
        "\n",
        "            # Vocabulary lookup for next input token\n",
        "            message_t = torch.argmax(y_t, dim=1)\n",
        "\n",
        "        # Concatenate outputs for the sequence\n",
        "        outputs = torch.cat(outputs, dim=1)\n",
        "        return outputs\n",
        "\n",
        "    def load_weights(self, weight_paths):\n",
        "        \"\"\"\n",
        "        Load weights from JSON files and assign them to model parameters.\n",
        "\n",
        "        Args:\n",
        "        weight_paths (dict): A dictionary containing file paths for each weight file.\n",
        "                             Expected keys: 'U_h_weight', 'U_h_bias', 'W_h_weight',\n",
        "                             'W_h_bias', 'W_y_weight', 'embedding_weight'.\n",
        "        \"\"\"\n",
        "        def load_weight_from_json(file_path):\n",
        "            with open(file_path, 'r') as f:\n",
        "                weight_data = json.load(f)\n",
        "            return torch.tensor(weight_data)\n",
        "\n",
        "        # Assign weights to the model's parameters\n",
        "        self.U_h.weight.data = load_weight_from_json(weight_paths['U_h_weight'])\n",
        "        self.U_h.bias.data = load_weight_from_json(weight_paths['U_h_bias'])\n",
        "        self.W_h.weight.data = load_weight_from_json(weight_paths['W_h_weight'])\n",
        "        self.W_h.bias.data = load_weight_from_json(weight_paths['W_h_bias'])\n",
        "        self.W_y.weight.data = load_weight_from_json(weight_paths['W_y_weight'])\n",
        "        self.embedding.weight.data = load_weight_from_json(weight_paths['embedding_weight'])\n",
        "\n",
        "        print(\"Weights loaded successfully.\")\n",
        "\n",
        "    def forward_pass(self, start_index, end_index, max_sequence=100):\n",
        "        \"\"\"\n",
        "        Generate a sequence starting from `start_index` until reaching `end_index` or\n",
        "        until `max_sequence` length is reached.\n",
        "\n",
        "        Args:\n",
        "        start_index (int): The index of the starting token.\n",
        "        end_index (int): The index of the end token.\n",
        "        max_sequence (int): The maximum length of the generated sequence to prevent infinite loops.\n",
        "\n",
        "        Returns:\n",
        "        list: A list of token indices representing the generated sequence.\n",
        "        \"\"\"\n",
        "        sequence = [start_index]\n",
        "        h_t = torch.zeros(1, self.hidden_dim, device=self.embedding.weight.device)\n",
        "\n",
        "        current_index = start_index\n",
        "        for _ in range(max_sequence):\n",
        "            # Get the embedding of the current token\n",
        "            x_t = self.embedding(torch.tensor([current_index], device=self.embedding.weight.device))\n",
        "\n",
        "            # Update hidden state\n",
        "            h_t = torch.tanh(self.W_h(x_t) + self.U_h(h_t))\n",
        "\n",
        "            # Get the output and determine the next token\n",
        "            y_t = self.W_y(h_t)\n",
        "\n",
        "            current_index = torch.argmax(y_t, dim=-1).item()\n",
        "            sequence.append(current_index)\n",
        "\n",
        "            # Break if the end token is reached\n",
        "            if current_index == end_index:\n",
        "                break\n",
        "\n",
        "        return sequence\n",
        "\n",
        "# Example usage\n",
        "weight_paths = {\n",
        "    'U_h_weight': 'U_h.weight.json',\n",
        "    'U_h_bias': 'U_h.bias.json',\n",
        "    'W_h_weight': 'W_h.weight.json',\n",
        "    'W_h_bias': 'W_h.bias.json',\n",
        "    'W_y_weight': 'W_y.weight.json',\n",
        "    'embedding_weight': 'embedding.weight.json'\n",
        "}\n",
        "\n",
        "# Model instantiation\n",
        "embedding_dim = 48\n",
        "hidden_dim = 160\n",
        "vocab_size = 133\n",
        "model = ElmanRNN(embedding_dim, hidden_dim, vocab_size)\n",
        "model.load_weights(weight_paths)"
      ],
      "metadata": {
        "id": "rC61W1AxN39F",
        "outputId": "72f2d1b8-835a-4570-a3ff-69544a4d8da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, tokens):\n",
        "        self.tokens = tokens\n",
        "        self._itos = list(tokens)\n",
        "        self._stoi = {token: index for index, token in enumerate(self._itos)}\n",
        "\n",
        "    def stoi(self, token: str) -> int:\n",
        "        \"\"\"Return token index or `unk_index` if `token` is not in the vocab.\"\"\"\n",
        "        return self._stoi.get(token, None)\n",
        "\n",
        "    def itos(self, index: int) -> str:\n",
        "        \"\"\"Return token by its `index`.\"\"\"\n",
        "        return self._itos[index]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._itos)\n",
        "\n",
        "def vectorize(tokens, vocab: Vocabulary):\n",
        "    \"\"\"Convert a list of tokens to a tensor of indices.\"\"\"\n",
        "    return torch.tensor([vocab.stoi(token) for token in tokens], dtype=torch.long)\n",
        "\n",
        "# Load the vocabulary from a JSON file and initialize Vocabulary\n",
        "with open('vocab.json', 'r') as f:\n",
        "    tokens = json.load(f)\n",
        "\n",
        "vocab = Vocabulary(tokens=tokens)"
      ],
      "metadata": {
        "id": "fMzOGIkyQszU"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_index = vocab.stoi(\"[\")\n",
        "end_index = vocab.stoi(\"]\")\n",
        "\n",
        "# Generate sequence using forward_pass\n",
        "generated_sequence_indices = model.forward_pass(start_index=start_index, end_index=end_index)\n",
        "generated_sequence_tokens = [vocab.itos(idx) for idx in generated_sequence_indices]\n",
        "\n",
        "print(\"Generated sequence:\", \"\".join(generated_sequence_tokens))\n"
      ],
      "metadata": {
        "id": "5j49jilQY8yZ",
        "outputId": "ddec260e-18a8-44e4-a5ad-2b66fb427554",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated sequence: [ĞĞ°Ğ·Ğ²Ğ° Ñ‚Ñ€ĞµĞºÑƒ: https://www.youtube.com/watch?v=WTwPWIGMkvs]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab.answer(\"Ğ¦Ğµ Ñ– Ñ” Ğ¶Ğ¸Ñ‚Ñ‚Ñ\")"
      ],
      "metadata": {
        "id": "kLtcVwfnrtWN",
        "outputId": "33727b5e-b584-4aa9-b842-eea22f1f8b64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ° âœ…\n",
            "You did it! ğŸš€ Next step: https://tally.so/r/wMXM0p\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MEC8pAf2b2fs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}