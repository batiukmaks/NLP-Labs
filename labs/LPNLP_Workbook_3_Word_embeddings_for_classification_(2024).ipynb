{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "6bLSgXhBp_ik",
        "0qdP0X3Op_il",
        "0HMdK4nwp_in",
        "Q_5QUDc8p_io",
        "JWyNFYd7p_iq",
        "bnj-EyYPp_ir",
        "TDcdMxXLp_iu",
        "xORrcb8ap_iv",
        "XzQ3Q5Trp_iv",
        "oZGXRCNrlBde"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/batiukmaks/NLP-Labs/blob/main/labs/LPNLP_Workbook_3_Word_embeddings_for_classification_(2024).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiiDM1V8p_iX"
      },
      "source": [
        "# Workbook 03: Word embeddings for text classification\n",
        "\n",
        "У цій роботі ми використаємо word embeddings для тренування моделі класифікації текстів.\n",
        "\n",
        "Маємо побачити, як word embeddings особливо сильно допомогають, коли тренувальних даних небагато (а їх майже завжди небагато)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --ignore-installed http://nlp.band/static/pypy/lpnlp-2023.10.2-py3-none-any.whl"
      ],
      "metadata": {
        "id": "zBBM2S6_jI8r"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3BcrrZzDGZ6",
        "outputId": "2a6ba06d-42ce-4a22-dbdc-a7cb8e3e4392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import lpnlp\n",
        "lab = lpnlp.start(\n",
        "    email=\"maksym.batiuk.kn.2021@lpnu.ua\",  # <---------------------- Заповніть це поле\n",
        "    lab=\"using_word_embeddings\",\n",
        "    )\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Удачі!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdb5yxDGp_ig"
      },
      "source": [
        "# GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZQ5JifvDp_ig",
        "outputId": "94034693-2a2a-4056-85a5-eb271438ed13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KESE75BDp_ih"
      },
      "source": [
        "Повний GloVe містить 4,000,000 векторів і займає багато пам'яті. Щоб уникнути проблем з пам'ятю, залишимо лише 50,000 векторів найчастотніших слів. Це трохи знизить якість моделей, але це зараз не головне."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSPkhqoep_ih"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "glove = KeyedVectors.load(\"http://nlp.band/static/files/glove-50k.bin\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC899YNmp_ir"
      },
      "source": [
        "# Bag-of-embeddings\n",
        "\n",
        "Вектори слів, натреновані на великому корпусі текстів, використовують для представлення слів замість розріджених one-hot, які ми бачили в першій лабораторній. Word embeddings чудово працюють з нейронним мережами різноманітних архітектур. Але зараз ми розглянемо напростіше використання: логістичну регресію (так, знову) та мішок векторів (bag-of-embeddings).\n",
        "\n",
        "В bag-of-embeddings ми усереднюємо вектори всіх слів, які входять в речення. Результат — вектор такої ж розмірності, як і вектор слова. Цей вектор кодує зміст усього речення. Звичайно, таке представлення не враховує порядок слів, рівноцінно ставиться до важливих та допоміжних слів, а тому \"кодує\" воно зміст речення вельми приблизно. Проте цього достатньо для багатьох простих задач."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnj-EyYPp_ir"
      },
      "source": [
        "## Токенізація\n",
        "\n",
        "Для початку нам треба токенізувати корпус. Важливий момент: GloVe та інші word embeddings тренувалися кожен зі своїм токенізатором. Нам слід використовувати максимально схожий токенізатор. Інакше ми не зможемо знайти вектори для багатьох слів.\n",
        "\n",
        "Насамперед, GloVe тренувалися на тексті, приведеному до нижнього регістру. Також розбіжності можуть бути в кодуванні слів типу `I'll` (токенізується в два токени `I 'll` чи в один токен `I'll`?), `don't`, `I've` і подібних.\n",
        "\n",
        "Перевіримо, який варіант токенізації використовує GloVe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwSeYexXp_is",
        "outputId": "e1787388-ba6c-4ef4-a046-7c5b028fa00d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"don't\" in glove"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7PLcDlop_is",
        "outputId": "122e5de5-f1f5-479c-cdbb-cebaa3826e04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"n't\" in glove"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InXjt_Oap_is",
        "outputId": "ebc18ccc-1305-4de4-b9da-533307d12200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"I'll\" in glove"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIGf6CMdp_it",
        "outputId": "3b542629-9494-4346-f1de-ce30b8b7e592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"'ll\" in glove"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Zyzasep_it"
      },
      "source": [
        "Отже, маємо розбивати `don't` на два токени: `do` + `n't`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8pkOJMrp_it",
        "outputId": "536af254-c978-4ddf-da38-47adf65cb86f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy\n",
        "from typing import List\n",
        "\n",
        "\n",
        "spacy_nlp = spacy.blank(\"en\")\n",
        "\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "  \"\"\"Tokenize string with SpaCy. \"\"\"\n",
        "\n",
        "  tokens = spacy_nlp.tokenizer(text)\n",
        "  return [str(token).lower() for token in tokens]\n",
        "\n",
        "tokenize(\"I don't know\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'do', \"n't\", 'know']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDcdMxXLp_iu"
      },
      "source": [
        "## Векторизація одного документа\n",
        "\n",
        "Тепер можемо порахувати вектор для кожного документу в корпус. Цей вектор буде дорівнювати середньому від векторів окремих слів документа."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLbkwgWdp_iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0c16b5-ca24-447c-b48c-2494efd06cfe"
      },
      "source": [
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "def bag_of_embeddings(doc: str, embeddings: KeyedVectors) -> np.ndarray:\n",
        "    tokens = tokenize(doc)\n",
        "\n",
        "    ##################################################\n",
        "    doc_vector = np.average(\n",
        "        np.array([\n",
        "            embeddings[t]\n",
        "            for t in tokens\n",
        "            if t in embeddings\n",
        "        ]),\n",
        "        axis=0\n",
        "    )\n",
        "    ##################################################\n",
        "\n",
        "    return doc_vector\n",
        "\n",
        "\n",
        "doc_embedding = bag_of_embeddings(\"Hello world!\", glove)\n",
        "print(f\"Embedding: {doc_embedding}\")\n",
        "print(f\"Shape:     {doc_embedding.shape}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding: [ 0.41084     0.4957     -0.35982665 -0.40393332 -0.19768667  0.25433\n",
            " -0.51489997  0.086394    0.04418867  0.365309   -0.3562367   0.15675335\n",
            "  0.09240001  0.4017      0.00335334 -0.08881667 -0.37311664  0.5704167\n",
            "  0.04311933  0.34267667  0.47882667  1.489306    0.25857666 -0.19864707\n",
            "  0.10432333  0.125766    0.10343501 -0.28578332 -0.31660533  0.013828\n",
            " -0.07466667  0.13855    -0.32214698 -0.28048036 -0.41403     0.06308667\n",
            " -0.239556   -0.03680335 -0.141137   -0.0916     -0.16916066  0.5716353\n",
            " -0.3125367   0.07347333 -0.16953166  0.20232     0.60658664  0.06445\n",
            " -0.01957001  0.30074     0.21663667 -0.06867133  0.4030467   0.07233366\n",
            " -0.17247333  0.20601167 -0.39144    -0.02245933 -0.17295867 -0.19998033\n",
            "  0.234197   -0.29320666 -0.13344    -0.1644     -0.00662334  0.01097\n",
            " -0.00953534  0.5020967   0.42084002  0.03766001  0.46454334 -0.44661132\n",
            "  0.22226368  0.0327     -0.43126     0.00774    -0.15634833  0.3885993\n",
            " -0.38001335 -0.13208102  0.22859664 -0.39621338  0.24020332  0.41949666\n",
            " -0.6473667  -0.11796334  0.300212   -0.04890667  0.19057    -0.65398\n",
            " -0.09819666  0.09049634 -0.12865366 -0.19084066 -0.30180568  0.07661999\n",
            "  0.03418794 -0.029667   -0.14523333 -0.23192567  0.09882667  0.43341336\n",
            "  0.047808   -0.09808999  0.26746067 -0.234358    0.12239435  0.81658\n",
            " -0.4490467   0.5518833  -0.29156667 -0.33961263  0.30956998  0.06785334\n",
            " -0.4310867   0.300855    0.265036    0.6470366  -0.7136433   0.01400334\n",
            "  0.10547134 -0.07894     0.25629333 -0.21767335  0.250195   -0.59736663\n",
            "  0.2866867  -0.05228667  0.23764335 -0.49035335 -0.45085332 -0.51667\n",
            " -0.01609633 -0.32716    -0.22492333 -0.47330332 -0.15200032  0.20181668\n",
            " -0.24229133  0.18925601 -0.060564   -0.21973099  0.24457999 -0.28706333\n",
            "  0.66340667  0.27743337 -0.49113    -0.26614666 -0.22016667  0.50276667\n",
            "  0.48637667  0.28844333 -0.2935419   0.45673665  0.23382999  0.5161\n",
            " -0.19783266 -0.18264268  0.019692   -0.013066    0.08293099  0.02575266\n",
            " -0.05760333 -0.30384     0.28910998 -0.30737334 -0.07102667 -0.11787966\n",
            " -0.35104668 -0.23236667  0.15019666 -0.01766733  0.6193733   0.16082667\n",
            " -0.11402833  0.14723666 -0.69580334 -0.23911469  0.234387    0.35806334\n",
            "  1.4951667  -0.21275432 -0.30564666  0.17912032 -0.31634    -0.6953034\n",
            "  0.20261668  0.47446966  0.2579     -0.62838    -0.13436668 -0.18600166\n",
            " -0.14682834  0.03335    -0.06864333 -0.24147433 -0.15195    -0.13681023\n",
            " -0.05313335  0.34631002]\n",
            "Shape:     (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Розмірність вектора документа не залежить від кількості слів у ньому:"
      ],
      "metadata": {
        "id": "ef2tBQytUvkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tests = [\n",
        "    \"Hello world\",\n",
        "    \"You can try the best you can. The best you can is good enough.\",\n",
        "]\n",
        "print(\"Розмір    Документ\")\n",
        "print(\"-\" * 80)\n",
        "for s in tests:\n",
        "    shape = bag_of_embeddings(\"Hello world!\", glove).shape\n",
        "    print(f\"{shape}    {s}\")"
      ],
      "metadata": {
        "id": "DNvRbFEoUz4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ebedc7-46b1-411b-bae3-25ed29c2b253"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Розмір    Документ\n",
            "--------------------------------------------------------------------------------\n",
            "(200,)    Hello world\n",
            "(200,)    You can try the best you can. The best you can is good enough.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab.checkpoint(\"`Hello world` centroid\", bag_of_embeddings(\"Hello world!\", glove).mean())"
      ],
      "metadata": {
        "id": "xKrsXe7DVPR8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4af7001-a107-4a3c-c4bc-690b34d02d6d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.0046237493'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove['hello'].shape"
      ],
      "metadata": {
        "id": "anbYSR9l2wqQ",
        "outputId": "d101790f-ca30-4413-f6a6-41cc091780e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRL0YDoop_iu"
      },
      "source": [
        "# Векторизація всього корпусу\n",
        "\n",
        "Наступна операція може зайняти пару хвилин:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3YZqlcOvkV3"
      },
      "source": [
        "!pip install --quiet datasets"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QWs_M95p_iu"
      },
      "source": [
        "import datasets\n",
        "imdb = datasets.load_dataset(\"imdb\")\n",
        "\n",
        "valid_data = imdb[\"test\"].shuffle(seed=1).filter(lambda x, i: i < 2000, with_indices=True)  # take 2000 random rows for validation\n",
        "train_data = imdb[\"train\"].shuffle(seed=2)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def vectorize_dataset(dataset: datasets.Dataset) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Векторізує весь датасет у представлення bag-of-embeddings.\n",
        "\n",
        "    Повертає матрицю ознак X та вектор класів y.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    for doc in tqdm(dataset):\n",
        "        doc_vector = bag_of_embeddings(doc[\"text\"], glove)\n",
        "        X.append(doc_vector)\n",
        "\n",
        "    X = np.stack(X)\n",
        "    y = np.array(dataset[\"label\"])\n",
        "    return (X, y)"
      ],
      "metadata": {
        "id": "uMDsl8LPUfZ2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxA_y-PPp_iu",
        "outputId": "7a04f9be-8d71-4170-88b3-0981519ba138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_boe, y_train_boe = vectorize_dataset(train_data)\n",
        "X_valid_boe, y_valid_boe = vectorize_dataset(valid_data)\n",
        "lab.checkpoint(\"Vectorized dataset shape\", X_train_boe.shape)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25000/25000 [01:19<00:00, 315.83it/s]\n",
            "100%|██████████| 2000/2000 [00:03<00:00, 509.77it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FK-cMukZZqUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xORrcb8ap_iv"
      },
      "source": [
        "## Logistic regression + Bag-of-Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Штучно обмежимо кількість тренувальних прикладів цим значенням.\n",
        "# Так ми емулюємо ситуацію, коли в нас мало тренувальних даних.\n",
        "TRAIN_SIZE = 500"
      ],
      "metadata": {
        "id": "43OKsPYeWlw8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iftv_Jq9p_iv",
        "outputId": "6d6e453e-3e5d-473f-f192-3670cb873278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Тренуємо логістичну регресію\n",
        "logreg = LogisticRegression(solver=\"liblinear\")\n",
        "\n",
        "logreg.fit(X_train_boe[:TRAIN_SIZE,], y_train_boe[:TRAIN_SIZE,])\n",
        "logreg_acc = logreg.score(X_valid_boe, y_valid_boe)\n",
        "lab.checkpoint(f\"LogReg + BoE accuracy on {TRAIN_SIZE}\", logreg_acc)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7325"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic regression + TF-IDF\n",
        "\n",
        "Натренуємо для порівняння модель на TF-IDF bag-of-ngrams ознаках. Тренувальні дані точнісінько такі, як і у моделі bag-of-embeddings. Але як щодо якості?\n"
      ],
      "metadata": {
        "id": "vJBKiOWBfnr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "X_train_bow = vectorizer.fit_transform(train_data[:TRAIN_SIZE][\"text\"])\n",
        "\n",
        "model_tfidf = LogisticRegression(solver='liblinear', C=0.2, penalty=\"l1\")\n",
        "model_tfidf.fit(X_train_bow, train_data[\"label\"][:TRAIN_SIZE])\n",
        "\n",
        "\n",
        "X_valid_bow = vectorizer.transform(valid_data[\"text\"])\n",
        "y_valid_bow = valid_data[\"label\"]\n",
        "tfidf_acc = model_tfidf.score(X_valid_bow, y_valid_bow)\n",
        "lab.checkpoint(f\"LogReg + TF-IDF accuracy on {TRAIN_SIZE}\", tfidf_acc)"
      ],
      "metadata": {
        "id": "K-I-Ij3_Gzbw",
        "outputId": "1cc1d308-5ac6-4185-8714-fef71906e41e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5035"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання\n",
        "\n",
        "Перетренуйте моделі на різних розмірах `TRAIN_SIZE`. Спробуйте кілька значень. Зверніть увагу, як різницю між моделями змінюється в залежності від `TRAIN_SIZE`.\n",
        "\n",
        "❗ Результат (посилання на ваш Google Colab або PDF) відправте на пошту oleksii.o.syvokon@lpnu.ua ❗"
      ],
      "metadata": {
        "id": "UhrxAf4IgT5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logreg_bag_of_embeddings(train_size):\n",
        "    logreg = LogisticRegression(solver=\"liblinear\")\n",
        "\n",
        "    logreg.fit(X_train_boe[:train_size,], y_train_boe[:train_size,])\n",
        "    logreg_acc = logreg.score(X_valid_boe, y_valid_boe)\n",
        "    return logreg_acc\n",
        "\n",
        "def test_logreg_tf_idf(train_size):\n",
        "    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "    X_train_bow = vectorizer.fit_transform(train_data[:train_size][\"text\"])\n",
        "\n",
        "    model_tfidf = LogisticRegression(solver='liblinear', C=0.2, penalty=\"l1\")\n",
        "    model_tfidf.fit(X_train_bow, train_data[\"label\"][:train_size])\n",
        "\n",
        "\n",
        "    X_valid_bow = vectorizer.transform(valid_data[\"text\"])\n",
        "    y_valid_bow = valid_data[\"label\"]\n",
        "    tfidf_acc = model_tfidf.score(X_valid_bow, y_valid_bow)\n",
        "    return tfidf_acc\n",
        "\n",
        "results = []\n",
        "for train_size in [100, 200, 500, 1000, 5000, 10000, 20000, 25000]:\n",
        "    logreg_acc = test_logreg_bag_of_embeddings(train_size)\n",
        "    tfidf_acc = test_logreg_tf_idf(train_size)\n",
        "    results.append((train_size, logreg_acc, tfidf_acc))\n",
        "\n",
        "    print(f\"LogReg + BoE accuracy on {train_size}\", logreg_acc)\n",
        "    print(f\"LogReg + TF-IDF accuracy on {train_size}\", tfidf_acc)\n",
        "    print()"
      ],
      "metadata": {
        "id": "gGFWQD8E6HWD",
        "outputId": "6b1e87e1-c65c-4efd-bb4d-34d3476d65ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogReg + BoE accuracy on 100 0.6285\n",
            "LogReg + TF-IDF accuracy on 100 0.5035\n",
            "\n",
            "LogReg + BoE accuracy on 200 0.6975\n",
            "LogReg + TF-IDF accuracy on 200 0.5035\n",
            "\n",
            "LogReg + BoE accuracy on 500 0.7325\n",
            "LogReg + TF-IDF accuracy on 500 0.5035\n",
            "\n",
            "LogReg + BoE accuracy on 1000 0.773\n",
            "LogReg + TF-IDF accuracy on 1000 0.5035\n",
            "\n",
            "LogReg + BoE accuracy on 5000 0.803\n",
            "LogReg + TF-IDF accuracy on 5000 0.7415\n",
            "\n",
            "LogReg + BoE accuracy on 10000 0.805\n",
            "LogReg + TF-IDF accuracy on 10000 0.8\n",
            "\n",
            "LogReg + BoE accuracy on 20000 0.8135\n",
            "LogReg + TF-IDF accuracy on 20000 0.8295\n",
            "\n",
            "LogReg + BoE accuracy on 25000 0.8135\n",
            "LogReg + TF-IDF accuracy on 25000 0.8365\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "diff_acc_df = pd.DataFrame(results, columns=['train_size', 'logreg_acc', 'tfidf_acc'])\n",
        "diff_acc_df['diff'] = diff_acc_df['logreg_acc'] - diff_acc_df['tfidf_acc']\n",
        "diff_acc_df"
      ],
      "metadata": {
        "id": "ssHVHQyu6pR6",
        "outputId": "b431f24f-27bc-44d8-e82d-3531d19dd6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   train_size  logreg_acc  tfidf_acc    diff\n",
              "0         100      0.6285     0.5035  0.1250\n",
              "1         200      0.6975     0.5035  0.1940\n",
              "2         500      0.7325     0.5035  0.2290\n",
              "3        1000      0.7730     0.5035  0.2695\n",
              "4        5000      0.8030     0.7415  0.0615\n",
              "5       10000      0.8050     0.8000  0.0050\n",
              "6       20000      0.8135     0.8295 -0.0160\n",
              "7       25000      0.8135     0.8365 -0.0230"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37e79b92-501b-47b4-a885-aaf4fbe1d304\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train_size</th>\n",
              "      <th>logreg_acc</th>\n",
              "      <th>tfidf_acc</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>0.6285</td>\n",
              "      <td>0.5035</td>\n",
              "      <td>0.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>200</td>\n",
              "      <td>0.6975</td>\n",
              "      <td>0.5035</td>\n",
              "      <td>0.1940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500</td>\n",
              "      <td>0.7325</td>\n",
              "      <td>0.5035</td>\n",
              "      <td>0.2290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>0.7730</td>\n",
              "      <td>0.5035</td>\n",
              "      <td>0.2695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5000</td>\n",
              "      <td>0.8030</td>\n",
              "      <td>0.7415</td>\n",
              "      <td>0.0615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10000</td>\n",
              "      <td>0.8050</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.0050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20000</td>\n",
              "      <td>0.8135</td>\n",
              "      <td>0.8295</td>\n",
              "      <td>-0.0160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>25000</td>\n",
              "      <td>0.8135</td>\n",
              "      <td>0.8365</td>\n",
              "      <td>-0.0230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37e79b92-501b-47b4-a885-aaf4fbe1d304')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37e79b92-501b-47b4-a885-aaf4fbe1d304 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37e79b92-501b-47b4-a885-aaf4fbe1d304');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-199542da-268b-447b-9c78-c974eb001d72\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-199542da-268b-447b-9c78-c974eb001d72')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-199542da-268b-447b-9c78-c974eb001d72 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "diff_acc_df",
              "summary": "{\n  \"name\": \"diff_acc_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"train_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9811,\n        \"min\": 100,\n        \"max\": 25000,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          200,\n          10000,\n          100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logreg_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.067294097331893,\n        \"min\": 0.6285,\n        \"max\": 0.8135,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.6285,\n          0.6975,\n          0.805\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tfidf_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16198146664268198,\n        \"min\": 0.5035,\n        \"max\": 0.8365,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7415,\n          0.8365,\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1156789738889484,\n        \"min\": -0.02300000000000002,\n        \"max\": 0.2695000000000001,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.19400000000000006,\n          0.0050000000000000044,\n          0.125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Аналіз результатів**: З результатів бачимо, що при значенні `TRAIN_SIZE` від 100 до 1000 \"акуратність\" Логістичної Регресії зростає, а разом з нею і відрив від Логістичної Регресії + TF-IDF. Починаючи з `TRAIN_SIZE`=5000 ця різниця починає спадати і \"акуратність\" Логістичної Регресії + TF-IDF починає переганяти \"акуратність\" просто Логістичної Регресії\n",
        "\n",
        "Отже, варто використовувати TF-IDF на більших наборах даних"
      ],
      "metadata": {
        "id": "hbGV90yI8M6v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqUpPckk98gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVoUZm0lxGds"
      },
      "source": [
        "# Embeddings matrix\n",
        "\n",
        "Досі для доступу до векторів слів ми користувалися бібліотекою `gensim`, яка надавала нам інтерфейс словника (`dict`).\n",
        "\n",
        "Під капотом, вектори слів зберігаються в одній матриці розмірності $|V| \\times d$, де $|V|$ це розмір словника (скільки слів маємо), а $d$ — розмір вектора слова (в цій лабораторній було $d=200$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0a3Cxl9iDBn",
        "outputId": "2375c908-bb8e-4aff-f29a-c2f8d8d7c182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "glove.vectors.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VybrpjjOkrrR"
      },
      "source": [
        "В моделях глибинного навчання, як правило, справу мають саме з цією embeddings matrix.\n",
        "\n",
        "Розглянемо два способи отримати вектор потрібного слова з цієї матриці:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZGXRCNrlBde"
      },
      "source": [
        "## Vector-matrix multiplication\n",
        "\n",
        "Перший спосіб, це представити слово з індексом $i$ у вигляді one-hot вектора $o_i$. Тоді ембедінг потрібного слова можна отримати в результаті добутку\n",
        "\n",
        "$$e_i = \\text{E}^\\intercal o_i $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryDrswVlkoUk"
      },
      "source": [
        "import torch\n",
        "\n",
        "embeddings_matrix = torch.tensor(glove.vectors)\n",
        "\n",
        "def embed(token_index: int, embeddings_matrix: torch.tensor) -> torch.tensor:\n",
        "    vocab_size, embed_dim = embeddings_matrix.shape\n",
        "    one_hot = torch.zeros(vocab_size)\n",
        "    one_hot[token_index] = 1\n",
        "    return one_hot @ embeddings_matrix\n",
        "\n",
        "assert torch.allclose(\n",
        "    embed(42, embeddings_matrix),\n",
        "    torch.tensor(glove.vectors[42]))\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0xFJ6DUm6GW",
        "outputId": "a3120aab-6a28-44b7-c6c7-fef958be5bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "lab.checkpoint(\"The embedding of one-hot multiplication\",\n",
        "               embed(42, embeddings_matrix).sum())"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tensor(5.3482)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4vqXSL4m2gF"
      },
      "source": [
        "## nn.Embedding\n",
        "\n",
        "В PyTorch, як і в більшості deep learning frameworks, є спеціальна функція, яка повертає вектор з потрібним номером: `torch.nn.Embedding`. Вона імплементована більш ефективно, ніж спосіб з vector-matrix multiplication, тож в більшості випадків користуватися варто саме `nn.Embedding`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A29kVgWvrr9I"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "embeddings = nn.Embedding(num_embeddings=50_000, embedding_dim=200, _weight=embeddings_matrix)\n",
        "indexes = torch.LongTensor([42])\n",
        "embedded = embeddings(indexes)\n",
        "\n",
        "assert np.isclose(embedded.sum().item(), glove.vectors[42].sum())"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTBXxCdutJLG",
        "outputId": "dc8414a2-c097-4939-b430-bbac6bab1b97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lab.checkpoint(\"nn.Embeddings\", embedded.sum().item())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.34816837310791"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Готово!"
      ],
      "metadata": {
        "id": "7U97-goHHZrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lab.answer(\"ALL DONE! 😊\")"
      ],
      "metadata": {
        "id": "ZUariUJ2HiQ6",
        "outputId": "294db314-a2ce-439d-f30e-c1f9d903398f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Відповідь правильна ✅\n",
            "💪\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ALL DONE! 😊'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}