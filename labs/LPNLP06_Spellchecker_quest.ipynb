{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/batiukmaks/NLP-Labs/blob/main/labs/LPNLP06_Spellchecker_quest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spellchecker quest\n",
        "\n",
        "Хтось наробив помилок у віршах Тараса Шевченка. Наша задача -- виправити ці помилки і прочитати приховане повідомлення.\n",
        "\n",
        "## Задача\n",
        "\n",
        "Ви отримаєте тренувальні та тестувальні дані.\n",
        "\n",
        "Тренувальні дані знаходяться в полі `lab.train_text`. Це звичайний нерозмічений текст. На ньому необхідно натренувати мовну модель. Підійде будь-яка. Я би радив feed-forward нейрону модель з токенізацією по літерах, бо це те, що ми проходили на останній лекції. Але n-грамна теж має спрацювати.\n",
        "\n",
        "Тестувальні дані знаходиться в полі `lab.test_items`. Приклад одного елемента:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"text\": \"Співали б прозу, та по ножах,\",\n",
        "  \"error_start\": 23,\n",
        "  \"error_end\": 28,\n",
        "  \"error\": \"ножах\",\n",
        "  \"corrections\": [\n",
        "    \"ногах\",\n",
        "    \"йотах\",\n",
        "    \"єнотах\",\n",
        "    \"ножах\",\n",
        "    \"нотах\"\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "`error_start` та `error_end` вказують на місцезнаходження помилки в тексті (в символах). У данному прикладі, помилкою є `text[23:28]`, тобто слово \"ножах\".\n",
        "\n",
        "`corrections` -- це список можливих виправлень.\n",
        "\n",
        "Ваша задача -- обрати правильне виправлення серед запропонованих.\n",
        "\n",
        "\n",
        "## Приховане повідомлення\n",
        "\n",
        "Один приклад в `lab.test_items` дає можливість прочитати одну літеру прихованого повідомлення. Для цього знайдіть різницю між літерами слова з помилкою (`error`) та обраним виправленням. Надрукуйте цю літеру. Якщо слово з помилкою направді правильне, а таке теж буває, надрукуйте пробіл. Приклади:\n",
        "\n",
        "```\n",
        "Error               Correction     To print\n",
        "-------------------------------------------\n",
        "привіт               приліт        л\n",
        "пні                  поні          о\n",
        "баллет               балет         л\n",
        "привіт               привіт        (space)\n",
        "```\n",
        "\n",
        "Приховане повідомлення, яке ви побачите в результаті це рядок з віршу одного з українських авторів.\n",
        "\n",
        "Відповідь на квест -- ім'я автора/ки у форматі \"Ім'я Прізвище\".\n",
        "\n",
        "Полетіли! 🚀"
      ],
      "metadata": {
        "id": "L-Z5-FrvSNPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --ignore-installed http://nlp.band/static/pypy/lpnlp-2023.10.2-py3-none-any.whl"
      ],
      "metadata": {
        "id": "qa35VG1zj2wR",
        "outputId": "50f091f2-f974-4231-817e-25fafc003df6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lpnlp\n",
        "\n",
        "lab = lpnlp.start(\n",
        "    email=\"maksym.batiuk.kn.2021@lpnu.ua\",                   # <----------- Заповніть це поле\n",
        "    lab=\"quest_spellchecker\"\n",
        "    )"
      ],
      "metadata": {
        "id": "DjClbL-Hmcaq",
        "outputId": "5767a4d6-cd14-4b64-a920-d59c5293956e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Удачі!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "YXWCGzsBknSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Мовна модель\n",
        "\n",
        "Натренуйте свою мовну модель тут"
      ],
      "metadata": {
        "id": "CkQ69irsm_Ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(lab.train_text)"
      ],
      "metadata": {
        "id": "HFRrhQXUOIRq",
        "outputId": "1ea5ca42-b481-40bb-9418-b5996752dae7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "414268"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lab.train_text[:330])"
      ],
      "metadata": {
        "id": "DsyqC9fPnMGa",
        "outputId": "e86bbd74-690e-4eb8-e338-92777b649d3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿ПРИЧИННА\r\n",
            "\r\n",
            "Реве та стогне Дніпр широкий,\r\n",
            "Сердитий вітер завива,\r\n",
            "Додолу верби гне високі,\r\n",
            "Горами хвилю підійма.\r\n",
            "І блідий місяць на ту пору\r\n",
            "Із хмари де-де виглядав,\r\n",
            "Неначе човен в синім морі,\r\n",
            "То виринав, то потопав.\r\n",
            "Ще треті півні не співали,\r\n",
            "Ніхто нігде не гомонів,\r\n",
            "Сичі в гаю перекликались,\r\n",
            "Та ясен раз у раз скрипів.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "\n",
        "  def __init__(self, tokens, unk_token=\"<unk>\"):\n",
        "    self.unk_token = unk_token\n",
        "    self.unk_index = 0\n",
        "    self.tokens = [unk_token] + tokens\n",
        "    self._itos = [unk_token] + list(set(tokens))\n",
        "    self._stoi = {token: index for index, token in enumerate(self._itos)}\n",
        "\n",
        "  def stoi(self, token: str) -> int:\n",
        "    \"\"\"Return token index or `<unk>` index if `token` is not in the vocab.\n",
        "    \"\"\"\n",
        "    return self._stoi.get(token, self.unk_index)\n",
        "\n",
        "\n",
        "  def itos(self, index: int) -> str:\n",
        "    \"\"\"Return token by its `index`.\n",
        "\n",
        "    Raise LookupError if `index` is out of vocabulary range.\n",
        "    \"\"\"\n",
        "\n",
        "    return self._itos[index]\n",
        "\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self._itos)"
      ],
      "metadata": {
        "id": "SZ9gkbweJjRB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sequences(tokens, context_len):\n",
        "    for i in range(context_len, len(tokens)):\n",
        "        context = tokens[i - context_len : i]\n",
        "        target = tokens[i]\n",
        "\n",
        "        yield context, target\n",
        "\n",
        "def tokenize(text):\n",
        "    return list(text.lower())\n",
        "\n",
        "def vectorize(tokens, vocab: Vocabulary):\n",
        "    return torch.tensor([vocab.stoi(token) for token in tokens], dtype=torch.long)"
      ],
      "metadata": {
        "id": "RS29tR5FLfSp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_size,\n",
        "            embed_dim,\n",
        "            context_len,\n",
        "            hidden_dim,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.context_len = context_len\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.W = nn.Linear(context_len * embed_dim, hidden_dim)\n",
        "        self.U = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, X_indices):\n",
        "        X = self.embed(X_indices)\n",
        "        e = X.view(-1, self.context_len * self.embed_dim)\n",
        "\n",
        "        h = torch.tanh(self.W(e)) # TODO: Consider other activation functions\n",
        "        logits = self.U(h)\n",
        "\n",
        "        log_probs = torch.log_softmax(logits, dim=-1)\n",
        "\n",
        "        return log_probs"
      ],
      "metadata": {
        "id": "H7nqH5ZiJ_kw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_it(sequences, batch_size, vocab):\n",
        "    batch_X = []\n",
        "    batch_y = []\n",
        "    for context, target in sequences:\n",
        "        batch_X.append(vectorize(context, vocab))\n",
        "        batch_y.append(vocab.stoi(target))\n",
        "\n",
        "        if len(batch_X) == batch_size:\n",
        "            # Pad the sequences in batch_X\n",
        "            X_padded = pad_sequence(batch_X, batch_first=True)\n",
        "            yield X_padded, torch.tensor(batch_y, dtype=torch.long)\n",
        "            batch_X = []\n",
        "            batch_y = []\n",
        "\n",
        "    if batch_X:\n",
        "        X_padded = pad_sequence(batch_X, batch_first=True)\n",
        "        yield X_padded, torch.tensor(batch_y, dtype=torch.long)\n",
        "\n",
        "\n",
        "def train(\n",
        "        vocab,\n",
        "        vocab_size,\n",
        "        embed_dim,\n",
        "        context_len,\n",
        "        hidden_dim,\n",
        "        learning_rate,\n",
        "        num_epochs,\n",
        "        batch_size,\n",
        "):\n",
        "    model = Model(\n",
        "        vocab_size=vocab_size,\n",
        "        embed_dim=embed_dim,\n",
        "        context_len=context_len,\n",
        "        hidden_dim=hidden_dim,\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.NLLLoss()\n",
        "\n",
        "    sequences = list(get_sequences(vocab.tokens, context_len))\n",
        "    batches = list(batch_it(sequences, batch_size, vocab))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for X_batch, y_batch in tqdm(batches, leave=False):\n",
        "            optimizer.zero_grad()\n",
        "            log_probs = model(X_batch)\n",
        "            loss = loss_fn(log_probs.view(-1, model.vocab_size), y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"[Epoch {epoch + 1}/{num_epochs}] | Loss: {total_loss / len(sequences)}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "0vgKTU_HLXXR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Vocabulary(tokenize(lab.train_text))\n",
        "\n",
        "model = train(\n",
        "    vocab=vocab,\n",
        "    vocab_size=len(vocab),\n",
        "    embed_dim=64,\n",
        "    context_len=10,\n",
        "    hidden_dim=128,\n",
        "    learning_rate=0.001,\n",
        "    num_epochs=20,\n",
        "    batch_size=256\n",
        ")"
      ],
      "metadata": {
        "id": "tFb93XK8ErR7",
        "outputId": "e97e4fc9-dca0-4b20-9290-5b8d90375dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/20] | Loss: 0.008942597024767822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 2/20] | Loss: 0.007968766632973393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 3/20] | Loss: 0.007645278998222103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 4/20] | Loss: 0.0074587149498837975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 5/20] | Loss: 0.00733488782817987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 6/20] | Loss: 0.007244172021525596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 7/20] | Loss: 0.007174992296078447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 8/20] | Loss: 0.007118672623347413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 9/20] | Loss: 0.007071184887082296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10/20] | Loss: 0.00702978024898916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 11/20] | Loss: 0.00699347060854737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 12/20] | Loss: 0.00696160480250528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 13/20] | Loss: 0.006933546004644892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 14/20] | Loss: 0.006908525061398041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 15/20] | Loss: 0.006886438115456396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 16/20] | Loss: 0.006866633839254427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 17/20] | Loss: 0.006848597898688142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 18/20] | Loss: 0.006831793031967862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 19/20] | Loss: 0.006815969714795329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 20/20] | Loss: 0.006801056815374598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Читаємо між рядків"
      ],
      "metadata": {
        "id": "USBCYglkn_WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import collections\n",
        "from typing import List, Tuple\n",
        "\n",
        "\n",
        "# Допоміжна фунція:\n",
        "def get_letter(w1: str, w2: str) -> str:\n",
        "    \"\"\"Повертає літеру, якої відрізняються слова або пробіл для однакових слів.\n",
        "    \"\"\"\n",
        "\n",
        "    letters1 = collections.Counter(w1)\n",
        "    letters2 = collections.Counter(w2)\n",
        "\n",
        "    diff = letters1 - letters2\n",
        "    if len(diff) != 1:\n",
        "        return \" \"\n",
        "\n",
        "    return diff.most_common()[0][0]\n",
        "\n",
        "\n",
        "def score_text(text: str, model, vocab) -> float:\n",
        "    \"\"\"Повертає perplexity або log-probability для тексту. \"\"\"\n",
        "\n",
        "    tokens = tokenize(text)\n",
        "    total_log_prob = 0.0\n",
        "\n",
        "    for context, target in get_sequences(tokens, model.context_len):\n",
        "        X = vectorize(context, vocab)\n",
        "        target = vectorize([target], vocab)[0]\n",
        "        log_probs = model(X)\n",
        "        target_log_prob = log_probs[0, target]\n",
        "        total_log_prob += target_log_prob\n",
        "\n",
        "    return torch.exp(-torch.tensor(total_log_prob) / len(tokens)).item()\n",
        "\n",
        "# Можете змінювати параметри та весь цей код, якщо потрібно\n",
        "def solve(model, vocab, test_items) -> Tuple[List[str], str]:\n",
        "    \"\"\"Повертає список виправлених слів для кожного з текстів в test_items та\n",
        "    секретне повідомлення.\n",
        "    \"\"\"\n",
        "\n",
        "    choices = []\n",
        "    secret = []\n",
        "\n",
        "    for item in test_items:\n",
        "        scores = []\n",
        "        for corr in item['corrections']:\n",
        "\n",
        "            # Підставляємо слово-кандидат в текст\n",
        "            text = item['text'][:item['error_start']] + corr + item['text'][item['error_end']:]\n",
        "\n",
        "            # Рахуємо score тексту\n",
        "            score = score_text(text, model, vocab)\n",
        "            scores.append(score)\n",
        "\n",
        "            # print(f'{score:.4f} {text}')\n",
        "\n",
        "        # Сортуємо кандидатів на виправлення за score\n",
        "        result = sorted(zip(scores, item['corrections']), key=lambda x: x[0])\n",
        "\n",
        "        # Обираємо найкращу заміну\n",
        "        best = result[0]\n",
        "        best_word = best[1]\n",
        "        choices.append(best_word)\n",
        "\n",
        "        # Знаходимо чергову літеру повідомлення\n",
        "        error = item['error']\n",
        "        letter = get_letter(error, best_word)\n",
        "        secret.append(letter)\n",
        "\n",
        "    secret_message = ''.join(secret)\n",
        "\n",
        "    return choices, secret_message\n",
        "\n",
        "choices, secret_message = solve(model, vocab, lab.test_items)\n",
        "\n",
        "lab.evaluate_accuracy(choices)\n",
        "print(\"SECRET MESSAGE: \", secret_message)\n"
      ],
      "metadata": {
        "id": "suXDePt3pLZ7",
        "outputId": "532a02af-1f7c-4c06-85e9-81badbbb4d22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-6cc23526443e>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.exp(-torch.tensor(total_log_prob) / len(tokens)).item()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Відповідь правильна ✅\n",
            "accuracy = 0.66. Непогано! Спробуй розгадай приховане повідомлення\n",
            "SECRET MESSAGE:   Зй правда кр ла     рунту н  тРебажзем   Не аєртор уде  ебо не    п ля т  б де  оля нем   Пари то  уду   х ари   цьом   апев   пра д  пт шина а як  е люд на а що ж л д на   ве н    млі  амар   літає   к и а ма    кр ла м єивони ті  р ла н  з пу уп р'  арз пр в и чес о   і дов р'  утк     з вірності у   ханні у когом зт ічногоіП риванзяіу  ог  ззощ рост о о Р б ти убкОго  з  е роСт  н  турботи   кого пз піСні або з  а ії аб ез поезії     З мріїолюдин   і и очне   т єо  к ил  ма  аакр л к а \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab.answer(\"Ліна Костенко\")"
      ],
      "metadata": {
        "id": "S7Hmxf6YqUVR",
        "outputId": "e21ebc57-03b9-45b4-b3b6-6dc4d89593c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Відповідь правильна ✅\n",
            "Правильно! 🚀 Заповни тепер цю форму, будь ласка: https://tally.so/r/wkl0zZ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Відправте посилання на цей colab або PDF з ним на пошту oleksii.o.syvokon@lpnu.ua. Дякую!\n"
      ],
      "metadata": {
        "id": "VpE_-wtdpkHe"
      }
    }
  ]
}